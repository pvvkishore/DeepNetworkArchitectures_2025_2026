{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68a6621-5b5e-4c7f-85ff-0353731aafce",
   "metadata": {},
   "source": [
    "# AIM: To design a ANN model for classification of Data and compute the performace metrics by eveluating the trained model. Also analyze its performance on real data by plotting the performace metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0b31b-7c78-4864-b5f6-a1fe444a67c7",
   "metadata": {},
   "source": [
    "# Use Pytorch Framework and NumPy, Pandas and matplotlib libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddac2fb-73d1-4270-8b21-29ed74e89a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c75099-464f-426a-ac80-143c0219c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafd6e9-ad0b-4017-8611-ef140d013580",
   "metadata": {},
   "source": [
    "# Define dataset: OR Gate / Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc213106-7f43-4d73-b5ba-1d4752735066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
    "y = torch.tensor([[0.0],[1.0],[1.0],[1.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb6eeca-3d48-405a-aafb-4c93c52be117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca866db-d90f-472b-b064-4148a99233b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7078bce4-5bbe-4259-890a-8554220f54e5",
   "metadata": {},
   "source": [
    "# Construct or Design a Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d88fb61-f5ab-4de0-8dfd-0db82aba8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OR_ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OR_ANN, self).__init__()\n",
    "        self.linear = nn.Linear(2,1) # Inputs =2 output = 1\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad927d-db3e-4945-bd1f-100793cd478b",
   "metadata": {},
   "source": [
    "# Instanciate the model with loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928afc77-1afa-40d8-a89e-f42ab31e250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OR_ANN()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee52545-1722-4269-b5ff-0b6d341ae478",
   "metadata": {},
   "source": [
    "# Now Lets Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469f8740-2ee1-4724-bfe8-e2ea73ab09ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc51d6ad-82d6-47a9-9e3c-60a017903c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])  # Input combinations\n",
    "labels = torch.tensor([[0.0], [1.0], [1.0], [1.0]])  # Corresponding outputs for OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9bc68a-e17e-45f7-a3c4-b7a53dc031a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.6774\n",
      "Epoch [20/1000], Loss: 0.5579\n",
      "Epoch [30/1000], Loss: 0.4954\n",
      "Epoch [40/1000], Loss: 0.4580\n",
      "Epoch [50/1000], Loss: 0.4324\n",
      "Epoch [60/1000], Loss: 0.4130\n",
      "Epoch [70/1000], Loss: 0.3972\n",
      "Epoch [80/1000], Loss: 0.3836\n",
      "Epoch [90/1000], Loss: 0.3714\n",
      "Epoch [100/1000], Loss: 0.3602\n",
      "Epoch [110/1000], Loss: 0.3499\n",
      "Epoch [120/1000], Loss: 0.3401\n",
      "Epoch [130/1000], Loss: 0.3310\n",
      "Epoch [140/1000], Loss: 0.3223\n",
      "Epoch [150/1000], Loss: 0.3140\n",
      "Epoch [160/1000], Loss: 0.3062\n",
      "Epoch [170/1000], Loss: 0.2987\n",
      "Epoch [180/1000], Loss: 0.2915\n",
      "Epoch [190/1000], Loss: 0.2846\n",
      "Epoch [200/1000], Loss: 0.2780\n",
      "Epoch [210/1000], Loss: 0.2717\n",
      "Epoch [220/1000], Loss: 0.2656\n",
      "Epoch [230/1000], Loss: 0.2598\n",
      "Epoch [240/1000], Loss: 0.2542\n",
      "Epoch [250/1000], Loss: 0.2489\n",
      "Epoch [260/1000], Loss: 0.2437\n",
      "Epoch [270/1000], Loss: 0.2387\n",
      "Epoch [280/1000], Loss: 0.2340\n",
      "Epoch [290/1000], Loss: 0.2293\n",
      "Epoch [300/1000], Loss: 0.2249\n",
      "Epoch [310/1000], Loss: 0.2206\n",
      "Epoch [320/1000], Loss: 0.2165\n",
      "Epoch [330/1000], Loss: 0.2125\n",
      "Epoch [340/1000], Loss: 0.2086\n",
      "Epoch [350/1000], Loss: 0.2049\n",
      "Epoch [360/1000], Loss: 0.2013\n",
      "Epoch [370/1000], Loss: 0.1978\n",
      "Epoch [380/1000], Loss: 0.1944\n",
      "Epoch [390/1000], Loss: 0.1911\n",
      "Epoch [400/1000], Loss: 0.1879\n",
      "Epoch [410/1000], Loss: 0.1848\n",
      "Epoch [420/1000], Loss: 0.1818\n",
      "Epoch [430/1000], Loss: 0.1789\n",
      "Epoch [440/1000], Loss: 0.1761\n",
      "Epoch [450/1000], Loss: 0.1734\n",
      "Epoch [460/1000], Loss: 0.1707\n",
      "Epoch [470/1000], Loss: 0.1681\n",
      "Epoch [480/1000], Loss: 0.1656\n",
      "Epoch [490/1000], Loss: 0.1632\n",
      "Epoch [500/1000], Loss: 0.1608\n",
      "Epoch [510/1000], Loss: 0.1585\n",
      "Epoch [520/1000], Loss: 0.1562\n",
      "Epoch [530/1000], Loss: 0.1541\n",
      "Epoch [540/1000], Loss: 0.1519\n",
      "Epoch [550/1000], Loss: 0.1498\n",
      "Epoch [560/1000], Loss: 0.1478\n",
      "Epoch [570/1000], Loss: 0.1458\n",
      "Epoch [580/1000], Loss: 0.1439\n",
      "Epoch [590/1000], Loss: 0.1420\n",
      "Epoch [600/1000], Loss: 0.1402\n",
      "Epoch [610/1000], Loss: 0.1384\n",
      "Epoch [620/1000], Loss: 0.1366\n",
      "Epoch [630/1000], Loss: 0.1349\n",
      "Epoch [640/1000], Loss: 0.1333\n",
      "Epoch [650/1000], Loss: 0.1316\n",
      "Epoch [660/1000], Loss: 0.1300\n",
      "Epoch [670/1000], Loss: 0.1285\n",
      "Epoch [680/1000], Loss: 0.1269\n",
      "Epoch [690/1000], Loss: 0.1255\n",
      "Epoch [700/1000], Loss: 0.1240\n",
      "Epoch [710/1000], Loss: 0.1226\n",
      "Epoch [720/1000], Loss: 0.1212\n",
      "Epoch [730/1000], Loss: 0.1198\n",
      "Epoch [740/1000], Loss: 0.1185\n",
      "Epoch [750/1000], Loss: 0.1171\n",
      "Epoch [760/1000], Loss: 0.1159\n",
      "Epoch [770/1000], Loss: 0.1146\n",
      "Epoch [780/1000], Loss: 0.1134\n",
      "Epoch [790/1000], Loss: 0.1122\n",
      "Epoch [800/1000], Loss: 0.1110\n",
      "Epoch [810/1000], Loss: 0.1098\n",
      "Epoch [820/1000], Loss: 0.1087\n",
      "Epoch [830/1000], Loss: 0.1076\n",
      "Epoch [840/1000], Loss: 0.1065\n",
      "Epoch [850/1000], Loss: 0.1054\n",
      "Epoch [860/1000], Loss: 0.1043\n",
      "Epoch [870/1000], Loss: 0.1033\n",
      "Epoch [880/1000], Loss: 0.1023\n",
      "Epoch [890/1000], Loss: 0.1013\n",
      "Epoch [900/1000], Loss: 0.1003\n",
      "Epoch [910/1000], Loss: 0.0994\n",
      "Epoch [920/1000], Loss: 0.0984\n",
      "Epoch [930/1000], Loss: 0.0975\n",
      "Epoch [940/1000], Loss: 0.0966\n",
      "Epoch [950/1000], Loss: 0.0957\n",
      "Epoch [960/1000], Loss: 0.0948\n",
      "Epoch [970/1000], Loss: 0.0939\n",
      "Epoch [980/1000], Loss: 0.0931\n",
      "Epoch [990/1000], Loss: 0.0922\n",
      "Epoch [1000/1000], Loss: 0.0914\n"
     ]
    }
   ],
   "source": [
    "# Modify training loop to collect loss values\n",
    "losses = []\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce6dd7-579f-4fee-a674-2f5f5ffeb6fc",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e43718b-1b7a-408a-ac07-ca315cb8d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "Inputs:\n",
      " [[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]]\n",
      "Predicted Outputs:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Actual Outputs:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "tensor([[0.1901],\n",
      "        [0.9254],\n",
      "        [0.9272],\n",
      "        [0.9985]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(inputs)\n",
    "    predicted = (test_outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "    print(\"\\nTesting Results:\")\n",
    "    print(\"Inputs:\\n\", inputs.numpy())\n",
    "    print(\"Predicted Outputs:\\n\", predicted.numpy())\n",
    "    print(\"Actual Outputs:\\n\", labels.numpy())\n",
    "    print(test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5701dd-ee6d-4b69-930c-b64d9b3460c2",
   "metadata": {},
   "source": [
    "# Evaluation and Visualization: Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e2a9ca-67ff-4f86-a7c0-754b93779dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229551d7-03fe-43bc-b1f5-c55008fd4675",
   "metadata": {},
   "source": [
    "# Function to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfaae3d-57c8-43fd-8c70-c8c658a4c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, inputs, labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(labels.numpy().flatten(), predicted.numpy().flatten())\n",
    "        precision = precision_score(labels.numpy().flatten(), predicted.numpy().flatten())\n",
    "        recall = recall_score(labels.numpy().flatten(), predicted.numpy().flatten())\n",
    "        f1 = f1_score(labels.numpy().flatten(), predicted.numpy().flatten())\n",
    "\n",
    "\n",
    "        print(\"\\nPerformance Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "        print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(labels.numpy(), predicted.numpy())\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e83655-db9e-4cd3-9537-c71a4a3461d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "def plot_loss_curve(losses):\n",
    "    plt.plot(losses, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473d994-de2b-404d-bec2-c03983eef74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundary\n",
    "def plot_decision_boundary(model):\n",
    "    # Define the grid range for plotting\n",
    "    x_min, x_max = -0.5, 1.5\n",
    "    y_min, y_max = -0.5, 1.5\n",
    "    xx, yy = torch.meshgrid(torch.linspace(x_min, x_max, 100), torch.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Reshape the grid for model input\n",
    "    grid = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1)], dim=1)  # Shape: (10000, 2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(grid)  # Pass the grid through the model\n",
    "        Z = (outputs > 0.5).float().reshape(xx.shape)  # Convert outputs to binary and reshape\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plt.contourf(xx.numpy(), yy.numpy(), Z.numpy(), alpha=0.7, cmap=plt.cm.Paired)\n",
    "    plt.scatter(inputs[:, 0].numpy(), inputs[:, 1].numpy(), c=labels.numpy().flatten(), edgecolor=\"k\", cmap=plt.cm.Paired)\n",
    "    plt.title(\"Decision Boundary\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e9b3f-ce56-42a6-95be-07876725223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize\n",
    "evaluate_model(model, inputs, labels)\n",
    "plot_loss_curve(losses)\n",
    "plot_decision_boundary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01eef36-2e15-4312-8c1f-7c954c801eaa",
   "metadata": {},
   "source": [
    "# TO Replicate the same Code for XOR Gate with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f336b3-e50f-4594-8ea5-1c3dbbf6118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XOR Neural Network Model\n",
    "class XOR_ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XOR_ANN, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 2)  # 2 input features, 4 hidden units\n",
    "        self.output = nn.Linear(2, 1)  # 4 hidden units, 1 output\n",
    "        self.sigmoid = nn.Sigmoid()  # Activation function for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = torch.relu(x)  # ReLU activation for the hidden layer\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid activation for the output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0d9c5-2043-417b-8392-0e61c1162759",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([[0.0], [1.0], [1.0], [0.0]])  # Corresponding outputs for XOR gate\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = XOR_ANN()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 500 epochs\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad5688-7690-4b7c-9513-b7850abf6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize\n",
    "evaluate_model(model, inputs, labels)\n",
    "plot_loss_curve(losses)\n",
    "plot_decision_boundary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b57f6-306f-4e24-9722-c1b1137333ad",
   "metadata": {},
   "source": [
    "# On Real Built - in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a5b9d-bba3-4721-9f4f-7aa4c10300e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b114cf-008f-4378-8330-520b2a2a328b",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf8698-3cf6-4550-9836-969be5941b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: Sepal and petal lengths and widths\n",
    "y = iris.target  # Labels: Iris species (0, 1, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158e96f-6ec2-41b2-a717-910db002ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels if needed (already in numerical form for Iris dataset)\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)  # Standardize the features for better training performance\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf0b7c-fc64-4420-9467-b2f03bfc4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Long type for classification\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda04db9-8c4c-42c3-bae6-c9dbbd02d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67023b04-20e3-42c0-867c-5cc08a26ea80",
   "metadata": {},
   "source": [
    "# Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fdb26-4542-4308-a9ac-94be67486b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(IrisMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()  # Activation for hidden layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output layer (no activation since we use CrossEntropyLoss)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f04412-a1bb-43ed-903e-c47b2e69dbad",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c2721-12f7-4eb0-9338-42a0230b8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 16  # Arbitrary choice\n",
    "output_dim = len(iris.target_names)  # 3 classes for Iris species\n",
    "\n",
    "model = IrisMLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(X_train_tensor.size(0))\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(epoch_loss / len(X_train_tensor))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(X_train_tensor):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599628d-ec75-4f79-9a74-7125ba5bda60",
   "metadata": {},
   "source": [
    "# Evaluate the Model and Make predictions on the test tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bdcc0-13f6-4c2e-b8e0-3091e3828e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, y_pred = torch.max(outputs, 1)  # Predicted class\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test_tensor.numpy(), y_pred.numpy())\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_pred.numpy())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c0e64-e593-47d4-8145-b26c09e2d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.plot(losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562c2b5-a4d0-417c-8870-f4dd14c04704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b5d82-289e-4da1-943c-abf19d1e29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "# Classification report\n",
    "report = classification_report(y_test_np, y_pred_np, target_names=iris.target_names)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb9329-52f5-4591-a24d-9df407ea8b72",
   "metadata": {},
   "source": [
    "# plot decision boundary with moons dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498cdf2-24c1-4430-8769-4ce719b7a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fdc9c-1845-4bf8-be38-a36995c1af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset (binary classification)\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for MLP performance)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552a873-f225-4127-b263-0771ffa59a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonsMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MoonsMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f8254-a1eb-4eea-ad41-cfc6e3a7a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, criterion, and optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 1  # Binary classification\n",
    "model = MoonsMLP(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(X_train_tensor.size(0))\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(epoch_loss / len(X_train_tensor))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(X_train_tensor):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4b6f4-dbc8-41cb-82d5-69b910c30346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot decision boundary\n",
    "def plot_decision_boundary(model, X, y, plot_title=\"Decision Boundary\"):\n",
    "    # Create a grid of points to evaluate the model\n",
    "    h = .02  # Step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Flatten the grid and make predictions\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_points_tensor = torch.tensor(grid_points, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        Z = model(grid_points_tensor)\n",
    "        Z = Z.numpy().reshape(xx.shape)\n",
    "    \n",
    "    # Plot the contour and training data\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdBu)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', s=50, cmap=plt.cm.RdBu)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot the decision boundary for the test set\n",
    "plot_decision_boundary(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f2efa-ac3b-4c16-b823-b3228e1bd735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
